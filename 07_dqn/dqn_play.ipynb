{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [07] Play Deep-Q Learning in Pong\n",
    "\n",
    "### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, collections\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "import torch\n",
    "\n",
    "from lib import wrappers, dqn_model\n",
    "\n",
    "\n",
    "DEFAULT_ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "FPS = 25 # Frames-per-second: approximate speed of shown frames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "\n",
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 21.00\n",
      "Action counts: Counter({3: 913, 1: 206, 4: 203, 0: 182, 2: 69, 5: 57})\n"
     ]
    }
   ],
   "source": [
    "# Directories \n",
    "model_dir = 'models/'\n",
    "rec_dir = 'recordings/'\n",
    "model_file = os.path.join(model_dir, \"PongNoFrameskip-v4_19.dat\")\n",
    "\n",
    "# Environment, Monitor \n",
    "env = wrappers.make_env(DEFAULT_ENV_NAME)\n",
    "env = gym.wrappers.Monitor(env, rec_dir, force=True)\n",
    "\n",
    "# Create Network & load weights \n",
    "# `map_location` maps the loaded tensor from GPU to CPU \n",
    "net = dqn_model.DQN(env.observation_space.shape, env.action_space.n)\n",
    "state = torch.load(model_file, map_location=lambda stg, _: stg)\n",
    "net.load_state_dict(state, model_dir)\n",
    "\n",
    "state = env.reset()\n",
    "total_reward = 0.0\n",
    "c = collections.Counter() # Action counter \n",
    "\n",
    "while True:\n",
    "    \n",
    "    start_ts = time.time()\n",
    "    env.render()\n",
    "    \n",
    "    # Pass observation to agent and select action wiht maximum value \n",
    "    state_v = torch.tensor(np.array([state], copy=False))\n",
    "    q_vals = net(state_v).data.numpy()[0]\n",
    "    action = np.argmax(q_vals)\n",
    "    c[action] += 1\n",
    "    \n",
    "    # Take step & accumulate total reward \n",
    "    state, reward, done, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "    # ? \n",
    "    delta = 1 / FPS - (time.time() - start_ts)\n",
    "    if delta > 0:\n",
    "        time.sleep(delta)\n",
    "            \n",
    "print(\"Total reward: %.2f\" % total_reward)\n",
    "print(\"Action counts:\", c)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Play Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./recordings/openaigym.video.0.4778.video000000.mp4\" controls  width=\"300\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./recordings/openaigym.video.0.4778.video000000.mp4\", width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drl",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
